-------------------- 上傳 ----------------------

-moveFromLocal：從本地剪切粘貼到HDFS
hadoop fs  -moveFromLocal  ./shuguo.txt  /sanguo

-copyFromLocal：從本地文件系統中拷貝文件到HDFS路徑去
hadoop fs -copyFromLocal weiguo.txt /sanguo

-put：等同於copyFromLocal，生產環境更習慣用put
hadoop fs -put ./wuguo.txt /sanguo

-appendToFile：追加一個文件到已經存在的文件末尾

hadoop fs -appendToFile liubei.txt /sanguo/shuguo.txt

-------------------- 下載 ----------------------

-copyToLocal：從HDFS拷貝到本地
hadoop fs -copyToLocal /sanguo/shuguo.txt ./


-get：等同於copyToLocal，生產環境更習慣用get
hadoop fs -get /sanguo/shuguo.txt ./shuguo2.txt


-------------------- HDFS直接操作 ----------------------

查詢 NameNode 當前生效的配置
hdfs getconf -confKey dfs.blockreport.intervalMsec

檢查 HDFS 集群狀態，確保 DataNode、NameNode 運行正常。
hdfs dfsadmin -report

查看 HDFS 根目錄
hdfs dfs -ls /

-ls: 显示目錄信息
hadoop fs -ls /sanguo

-cat：显示文件內容
hadoop fs -cat /sanguo/shuguo.txt

查詢可用壓縮方式
hadoop checknative

執行自訂打包上傳的 java (指定類:com.example.mapReduce.WordCountDriver 參數1 參數2)
hadoop jar xxx.jar com.example.mapReduce.WordCountDriver /input /output

-chgrp、-chmod、-chown：Linux文件系統中的用法一樣，修改文件所屬權限
hadoop fs  -chgrp  root /sanguo/shuguo.txt
hadoop fs  -chmod  666  /sanguo/shuguo.txt
hadoop fs  -chown  root:root   /sanguo/shuguo.txt

-mkdir：創建路徑
hadoop fs -mkdir /jinguo

-cp：從HDFS的一個路徑拷貝到HDFS的另一個路徑
hadoop fs -cp /sanguo/shuguo.txt /jinguo

-mv：在HDFS目錄中移動文件
hadoop fs -mv /sanguo/weiguo.txt /jinguo
hadoop fs -mv /Lecture1.pdf /guoting.pdf
注：當目的地是目錄時，就是單純的移動文件。若目的地是文件，則相當於剪切過去再重命名。沒錯，給文件或目錄重命名的實質就是剪切並重命名，只不過路徑沒有發生變化只更改名字罷了。

-tail：显示一個文件的末尾1kb的數據
hadoop fs -tail /jinguo/shuguo.txt

-rm：刪除文件或文件夾
hadoop fs -rm /sanguo/shuguo.txt

-rm -r：遞歸刪除目錄及目錄裏面內容
hadoop fs -rm -r /sanguo

-du：統計文件夾的大小信息
hadoop fs -du /jinguo
hadoop fs -du -s -h

-setrep：設置HDFS中文件的副本數量
hadoop fs -setrep 10 /jinguo/shuguo.txt

oev查看Edits文件
hdfs oiv -p 文件類型 -i鏡像文件 -o 轉換後文件輸出路徑
hdfs oiv -p XML -i fsimage_0000000000000000010 -o fs.xml

hdfs oev -p 文件類型 -i編輯日誌 -o 轉換後文件輸出路徑
hdfs oev -p XML -i edits_0000000000000000003-0000000000000000010 -o edits.xml

開啟數據均衡的命令：
sbin/start-balancer.sh -threshold 10

停用數據均衡命令：
sbin/stop-balancer.sh

列出所有存儲策略:
hdfs storagepolicies -listPolicies

為指定路徑(數據存儲目錄)設置指定存儲策略
hdfs storagepolicies -setstoragePolicy -path xxx -policy xxx

獲取指定路徑(數據存儲目錄或文件)的存儲策略
hdfs storagepolicies -getStoragePolicy -path xxx

取消存儲策略
hdfs storagepolicies -unsetStoragePolicy -path xxx

查看文件塊的分佈
bin/hdfs fsck xxx -files -blocks -locations

查看集群節點
hadoop dfsadmin -report

-------------------- YARN 常用指令 ----------------------

列出所有Application：
yarn application -list

根據Application狀態過濾出指定Application，如過濾出已完成的Application：
Application的狀態有：ALL、NEW、NEW_SAVING、SUBMITTED、ACCEPTED、RUNNING、FINISHED、FAILED、KILLED。
yarn application -list -appStates FINISHED

殺掉某個Application：其中，application_id是一串形如application_1612577921195_0001的字符串。
yarn application -kill application-id

列出所有Application嘗試的列表：
yarn applicationattempt -list <ApplicationId>

打印ApplicationAttempt的狀態：
yarn applicationattempt -status <applicationAttemptId>

--查看日誌
查詢某個Application的日誌：
yarn logs -applicationId <application-id>

查詢container日誌：
yarn logs -applicationId <ApplicationId> -containerId <ContainerId>

--查看容器
列出所有容器：
yarn container -list <ApplicationAttemptId>

打印容器狀態：只有在任務運行的時候，才能看到container的狀態
       yarn container -status <ContainerId>

--查看節點狀態
列出所有節點：
yarn node -list -all

--rmadmin更新配置
加載隊列配置：可以實現對隊列配置信息的動態的修改，無需停機。
       yarn rmadmin -refreshQueues

--查看隊列
打印隊列信息：比如說yarn queue -status default，就是打印默認的隊列 會打印出隊列的狀態、當前容量等等。
yarn queue -status <QueueName>






